{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12911.45s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabpfn\n",
      "  Downloading tabpfn-2.0.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting torch<3,>=2.1 (from tabpfn)\n",
      "  Downloading torch-2.6.0-cp310-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: scikit-learn<1.7,>=1.2.0 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from tabpfn) (1.5.1)\n",
      "Requirement already satisfied: typing_extensions>=4.4.0 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from tabpfn) (4.12.2)\n",
      "Requirement already satisfied: scipy<2,>=1.11.1 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from tabpfn) (1.14.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from tabpfn) (2.2.3)\n",
      "Collecting einops<0.9,>=0.2.0 (from tabpfn)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting huggingface-hub<1,>=0.0.1 (from tabpfn)\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1,>=0.0.1->tabpfn) (3.13.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1,>=0.0.1->tabpfn)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1,>=0.0.1->tabpfn) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1,>=0.0.1->tabpfn) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1,>=0.0.1->tabpfn) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1,>=0.0.1->tabpfn) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from pandas<3,>=1.4.0->tabpfn) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from pandas<3,>=1.4.0->tabpfn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from pandas<3,>=1.4.0->tabpfn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from pandas<3,>=1.4.0->tabpfn) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from scikit-learn<1.7,>=1.2.0->tabpfn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from scikit-learn<1.7,>=1.2.0->tabpfn) (3.5.0)\n",
      "Collecting networkx (from torch<3,>=2.1->tabpfn)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from torch<3,>=2.1->tabpfn) (3.1.4)\n",
      "Collecting sympy==1.13.1 (from torch<3,>=2.1->tabpfn)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch<3,>=2.1->tabpfn)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->tabpfn) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from jinja2->torch<3,>=2.1->tabpfn) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub<1,>=0.0.1->tabpfn) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub<1,>=0.0.1->tabpfn) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub<1,>=0.0.1->tabpfn) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/diegoguarin/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub<1,>=0.0.1->tabpfn) (2024.8.30)\n",
      "Downloading tabpfn-2.0.7-py3-none-any.whl (127 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "Downloading torch-2.6.0-cp310-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, einops, torch, huggingface-hub, tabpfn\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.1\n",
      "    Uninstalling torch-2.0.1:\n",
      "      Successfully uninstalled torch-2.0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "hyperopt 0.2.5 requires cloudpickle, which is not installed.\n",
      "torchaudio 2.0.2 requires torch==2.0.1, but you have torch 2.6.0 which is incompatible.\n",
      "torchvision 0.15.2 requires torch==2.0.1, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed einops-0.8.1 fsspec-2025.3.0 huggingface-hub-0.29.3 mpmath-1.3.0 networkx-3.4.2 sympy-1.13.1 tabpfn-2.0.7 torch-2.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tabpfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "# Set the global font to be DejaVu Sans, size 10 (or any other sans-serif font of your choice!)\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['DejaVu Sans'],'size':20})\n",
    "\n",
    "# Set the font used for MathJax - more on this later\n",
    "rc('mathtext',**{'default':'regular'})\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score,ConfusionMatrixDisplay, balanced_accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, RocCurveDisplay,roc_auc_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut, GridSearchCV, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from numpy import sort\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE,BorderlineSMOTE,ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, EasyEnsembleClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1508,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load data\n",
    "DataControls = pd.read_csv('DataFromControls.csv')\n",
    "DataParkinsons = pd.read_csv('DataFromParkinsons.csv')\n",
    "DataRBD = pd.read_csv('DataFromRBD.csv')\n",
    "\n",
    "# Function to identify and remove outliers using IsolationForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original {np.int64(0): np.int64(19), np.int64(1): np.int64(16)}\n"
     ]
    }
   ],
   "source": [
    "# define data groups\n",
    "\n",
    "selectedCols = ['MeanAmplitude','MeanSpeed', 'amplitudeDecay','velocityDecay']\n",
    "\n",
    "X1 = DataControls[selectedCols].values.astype(float)\n",
    "y1 = [0]*len(X1)\n",
    "\n",
    "X2 = DataRBD[selectedCols].values.astype(float)\n",
    "y2 = [1]*len(X2)\n",
    "\n",
    "\n",
    "X3 = DataParkinsons[selectedCols].values.astype(float)\n",
    "y3 = [1]*len(X3)\n",
    "\n",
    "\n",
    "def remove_outliers(data):\n",
    "    iso = IsolationForest(contamination=0.1)\n",
    "    yhat = iso.fit_predict(data)\n",
    "    mask = yhat != -1\n",
    "    return data[mask, :]\n",
    "\n",
    "# Remove outliers from each group\n",
    "X1 = remove_outliers(X1)\n",
    "X2 = remove_outliers(X2)\n",
    "X3 = remove_outliers(X3)\n",
    "\n",
    "#for binary classification of RBD (1) vs healthy controls (0)\n",
    "XCR = np.concatenate([X1, X2], axis=0)\n",
    "yCR = np.array([0]*len(X1)+[1]*len(X2))\n",
    "\n",
    "#for binary classification of PD (1) vs healthy controls (0)\n",
    "XCP = np.concatenate([X1,X3], axis=0)\n",
    "yCP = np.array([0]*len(X1)+[1]*len(X3))\n",
    "\n",
    "#for binary classification of RBD (0) vs PD (1) \n",
    "XRP = np.concatenate([X2, X3], axis=0)\n",
    "yRP = np.array([0]*len(X2)+[1]*len(X3))\n",
    "\n",
    "X = np.concatenate([X1, X2, X3], axis=0)\n",
    "y = np.array(y1+y2+y3)\n",
    "\n",
    "\n",
    "unique, counts = np.unique(yRP, return_counts=True)\n",
    "print('original',dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train different binary models to classify the groups. We use the following models:\n",
    "- Logistic Regression\n",
    "- Support Vector Machines\n",
    "- Random Forest \n",
    "- Gradient Boosting\n",
    "\n",
    "\n",
    "The results of this analysis might vary from trial to trial as the SMOTE algorithm adds randomness to the data. Repeat the analysis many times to obtain an average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO Subject CV Accuracy: 0.85\n",
      "LOO Subject CV Accuracy: 0.82\n",
      "LOO Subject CV F1-score: 0.84\n",
      "LOO Subject CV recall: 0.83\n",
      "LOO Subject CV precision: 0.85\n",
      "LOO Subject CV sensitivity: 0.81\n",
      "LOO Subject CV specificity: 0.84\n",
      "LOO Subject CV Area under the ROC: 0.82\n",
      "[[36  7]\n",
      " [ 3 13]]\n"
     ]
    }
   ],
   "source": [
    "# Binary classification of PD (1) vs healthy controls (0)\n",
    "\n",
    "#Apply SMOTE and RandomUnderSampler\n",
    "over = SMOTE(random_state=1)\n",
    "under = RandomUnderSampler(random_state=42)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipe = Pipeline(steps=steps)\n",
    "\n",
    "# Define subjects\n",
    "subjects = DataControls['ID'].tolist() + DataParkinsons['ID'].tolist()\n",
    "\n",
    "# Create a dictionary to map each sample to its subject\n",
    "sample_to_subject = {i: subjects[i] for i in range(len(subjects))}\n",
    "\n",
    "# Define a function to get unique subjects\n",
    "def get_unique_subjects(y):\n",
    "    return list(set([sample_to_subject[i] for i in range(len(y))]))\n",
    "\n",
    "# Define a function to get indices for a given subject\n",
    "def get_subject_indices(subject, y):\n",
    "    return [i for i in range(len(y)) if sample_to_subject[i] == subject]\n",
    "\n",
    "# Get unique subjects\n",
    "unique_subjects = get_unique_subjects(yCP)\n",
    "\n",
    "\n",
    "#different models used \n",
    "\n",
    "# model, scale = LogisticRegression(class_weight='balanced'), True  ##need to scale data \n",
    "# model, scale = svm.SVC(class_weight='balanced'), True  ##need to scale data \n",
    "model, scale = RandomForestClassifier(n_estimators=5,class_weight='balanced'  ), False ##no need to scale data \n",
    "# model, scale = EasyEnsembleClassifier(n_estimators=20), False ##no need to scale data\n",
    "# model, scale =   XGBClassifier(objective= 'binary:logistic',seed=42,n_jobs=-1,nthread=1,early_stopping_rounds=None,eval_metric='logloss',use_label_encoder=False,verbosity=0,class_weight='balanced'), False\n",
    "\n",
    "# model, scale =  XGBClassifier(\n",
    "#     n_estimators=50,\n",
    "#     objective='binary:logistic',\n",
    "#     scale_pos_weight=(len(yCP) - np.sum(yCP)) / np.sum(yCP),\n",
    "#     max_delta_step=1,\n",
    "# ), False\n",
    "\n",
    "\n",
    "# Initialize list to store predictions\n",
    "predictions = []\n",
    "true_labels = []\n",
    "accuracies = []\n",
    "# Perform Leave-One-Subject-Out CV\n",
    "\n",
    "selected_cols = [0,1,2,3]\n",
    "selected_cols = [1,3]\n",
    "for subject in unique_subjects:\n",
    "\n",
    "    test_indices = get_subject_indices(subject, yCP)\n",
    "    train_indices = [i for i in range(len(yCP)) if i not in test_indices]\n",
    "\n",
    "    #test data from one subject\n",
    "    XCP = np.array(XCP)\n",
    "    X_test, y_test = XCP[:,selected_cols][test_indices,:], yCP[test_indices]\n",
    "    # Apply SMOTE to the training data\n",
    "    #SMOTE to augment the data\n",
    "    \n",
    "    # X_train, y_train = SMOTE().fit_resample(XCP[:,selected_cols][train_indices,:], yCP[train_indices])\n",
    "    X_train, y_train = pipe.fit_resample(XCP[:,selected_cols][train_indices,:], yCP[train_indices])\n",
    "    # X_train, y_train = XCP[train_indices], yCP[train_indices]\n",
    "    ## Scale the data\n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "        # Fit the model\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    predictions.extend(y_pred)\n",
    "    true_labels.extend(y_test)\n",
    "     # Calculate accuracy\n",
    "\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # print(len(y_test), subject, accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = balanced_accuracy_score(true_labels, predictions)\n",
    "f1score = f1_score(true_labels, predictions, average = 'weighted')\n",
    "recall = recall_score(true_labels, predictions, average = 'weighted')\n",
    "precision = precision_score(true_labels, predictions, average='weighted')\n",
    "tn, fp, fn, tp = confusion_matrix(true_labels, predictions).ravel()\n",
    "sensitivity = tp /(tp+fn)\n",
    "specificity = tn / (tn+fp)\n",
    "roc_auc = roc_auc_score(true_labels, predictions)\n",
    "print(f\"LOO Subject CV Accuracy: {np.mean(accuracies):.2f}\")\n",
    "print(f\"LOO Subject CV Accuracy: {accuracy:.2f}\")\n",
    "print(f\"LOO Subject CV F1-score: {f1score:.2f}\")\n",
    "print(f\"LOO Subject CV recall: {recall:.2f}\")\n",
    "print(f\"LOO Subject CV precision: {precision:.2f}\")\n",
    "print(f\"LOO Subject CV sensitivity: {sensitivity:.2f}\")\n",
    "print(f\"LOO Subject CV specificity: {specificity :.2f}\")\n",
    "print(f\"LOO Subject CV Area under the ROC: {roc_auc :.2f}\")\n",
    "print(confusion_matrix(true_labels, predictions))\n",
    "\n",
    "# roc_display = RocCurveDisplay.from_predictions(true_labels, predictions)\n",
    "# roc_display = RocCurveDisplay(fpr=roc_auc[0], tpr=roc_auc[1], roc_auc=roc_auc[2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results -- binary classification of PD (1) vs healthy controls (0)\n",
    "\n",
    "RandomForestClassifier(class_weight='balanced', n_estimators=5)\n",
    "SelectedCols = ['MeanSpeed','velocityDecay']\n",
    "LOO Subject CV Accuracy: 0.85\n",
    "LOO Subject CV Accuracy: 0.82\n",
    "LOO Subject CV F1-score: 0.84\n",
    "LOO Subject CV recall: 0.83\n",
    "LOO Subject CV precision: 0.85\n",
    "LOO Subject CV sensitivity: 0.81\n",
    "LOO Subject CV specificity: 0.84\n",
    "LOO Subject CV Area under the ROC: 0.82\n",
    "[[36  7]\n",
    " [ 3 13]]\n",
    "\n",
    "\n",
    "LogisticRegression(class_weight='balanced')\n",
    "SelectedCols = ['MeanSpeed','velocityDecay']\n",
    "LOO Subject CV Accuracy: 0.78\n",
    "LOO Subject CV Accuracy: 0.79\n",
    "LOO Subject CV F1-score: 0.79\n",
    "LOO Subject CV recall: 0.78\n",
    "LOO Subject CV precision: 0.82\n",
    "LOO Subject CV sensitivity: 0.81\n",
    "LOO Subject CV specificity: 0.77\n",
    "LOO Subject CV Area under the ROC: 0.79\n",
    "[[33 10]\n",
    " [ 3 13]]\n",
    "\n",
    "\n",
    "XGBClassifier\n",
    "SelectedCols = ['MeanSpeed','velocityDecay']\n",
    "LOO Subject CV Accuracy: 0.73\n",
    "LOO Subject CV Accuracy: 0.74\n",
    "LOO Subject CV F1-score: 0.74\n",
    "LOO Subject CV recall: 0.73\n",
    "LOO Subject CV precision: 0.78\n",
    "LOO Subject CV sensitivity: 0.75\n",
    "LOO Subject CV specificity: 0.72\n",
    "LOO Subject CV Area under the ROC: 0.74\n",
    "[[31 12]\n",
    " [ 4 12]]\n",
    "\n",
    "svm(class_weight='balanced')\n",
    "SelectedCols = ['MeanSpeed','velocityDecay']\n",
    "LOO Subject CV Accuracy: 0.73\n",
    "LOO Subject CV Accuracy: 0.68\n",
    "LOO Subject CV F1-score: 0.72\n",
    "LOO Subject CV recall: 0.71\n",
    "LOO Subject CV precision: 0.74\n",
    "LOO Subject CV sensitivity: 0.62\n",
    "LOO Subject CV specificity: 0.74\n",
    "LOO Subject CV Area under the ROC: 0.68\n",
    "[[32 11]\n",
    " [ 6 10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO Subject CV Accuracy: 0.80\n",
      "LOO Subject CV Accuracy: 0.78\n",
      "LOO Subject CV F1-score: 0.79\n",
      "LOO Subject CV recall: 0.79\n",
      "LOO Subject CV precision: 0.80\n",
      "LOO Subject CV sensitivity: 0.74\n",
      "LOO Subject CV specificity: 0.81\n",
      "LOO Subject CV Area under the ROC: 0.78\n",
      "[[35  8]\n",
      " [ 5 14]]\n"
     ]
    }
   ],
   "source": [
    "# Binary classification of RBD (1) vs healthy controls (0)\n",
    "    \n",
    "\n",
    "#Apply SMOTE and RandomUnderSampler\n",
    "over = SMOTE(random_state=1)\n",
    "under = RandomUnderSampler(random_state=42)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipe = Pipeline(steps=steps)\n",
    "\n",
    "# Define subjects\n",
    "subjects = DataControls['ID'].tolist() + DataRBD['ID'].tolist()\n",
    "\n",
    "# Create a dictionary to map each sample to its subject\n",
    "sample_to_subject = {i: subjects[i] for i in range(len(subjects))}\n",
    "\n",
    "# Define a function to get unique subjects\n",
    "def get_unique_subjects(y):\n",
    "    return list(set([sample_to_subject[i] for i in range(len(y))]))\n",
    "\n",
    "# Define a function to get indices for a given subject\n",
    "def get_subject_indices(subject, y):\n",
    "    return [i for i in range(len(y)) if sample_to_subject[i] == subject]\n",
    "\n",
    "# Get unique subjects\n",
    "unique_subjects = get_unique_subjects(yCR)\n",
    "\n",
    "\n",
    "# model, scale = LogisticRegression(class_weight='balanced'), True ##need to scale data \n",
    "# model, scale = svm.SVC(class_weight='balanced'), True  ##need to scale data \n",
    "model, scale = RandomForestClassifier(n_estimators=20, class_weight='balanced'), False ##no need to scale data \n",
    "# model, scale = EasyEnsembleClassifier(n_estimators=20), False ##no need to scale data\n",
    "\n",
    "# model, scale =  XGBClassifier(\n",
    "#     n_estimators=30,\n",
    "#     objective='binary:logistic',\n",
    "#     scale_pos_weight=(len(yCR) - np.sum(yCR)) / np.sum(yCR),\n",
    "#     max_delta_step=1,\n",
    "# ), False\n",
    "\n",
    "# Initialize list to store predictions\n",
    "predictions = []\n",
    "true_labels = []\n",
    "accuracies = []\n",
    "# Perform Leave-One-Subject-Out CV\n",
    "\n",
    "selected_cols = [0,1,2,3]\n",
    "selected_cols = [1,3] \n",
    "for subject in unique_subjects:\n",
    "\n",
    "    test_indices = get_subject_indices(subject, yCR)\n",
    "    train_indices = [i for i in range(len(yCR)) if i not in test_indices]\n",
    "\n",
    "    #test data from one subject\n",
    "    XCR = np.array(XCR)\n",
    "    X_test, y_test = XCR[:,selected_cols][test_indices,:], yCR[test_indices]\n",
    "    # Apply SMOTE to the training data\n",
    "    #SMOTE to augment the data\n",
    "    \n",
    "    # X_train, y_train = SMOTE().fit_resample(XCR[:,selected_cols][train_indices,:], yCR[train_indices])\n",
    "    X_train, y_train = pipe.fit_resample(XCR[:,selected_cols][train_indices,:], yCR[train_indices])\n",
    "    # X_train, y_train = XCR[:,selected_cols][train_indices,:], yCP[train_indices]\n",
    "    ## Scale the data\n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "        # Fit the model\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    predictions.extend(y_pred)\n",
    "    true_labels.extend(y_test)\n",
    "     # Calculate accuracy\n",
    "\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # print(len(y_test), subject, accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = balanced_accuracy_score(true_labels, predictions)\n",
    "f1score = f1_score(true_labels, predictions, average = 'weighted')\n",
    "recall = recall_score(true_labels, predictions, average = 'weighted')\n",
    "precision = precision_score(true_labels, predictions, average='weighted')\n",
    "tn, fp, fn, tp = confusion_matrix(true_labels, predictions).ravel()\n",
    "sensitivity = tp /(tp+fn)\n",
    "specificity = tn / (tn+fp)\n",
    "roc_auc = roc_auc_score(true_labels, predictions)\n",
    "print(f\"LOO Subject CV Accuracy: {np.mean(accuracies):.2f}\")\n",
    "print(f\"LOO Subject CV Accuracy: {accuracy:.2f}\")\n",
    "print(f\"LOO Subject CV F1-score: {f1score:.2f}\")\n",
    "print(f\"LOO Subject CV recall: {recall:.2f}\")\n",
    "print(f\"LOO Subject CV precision: {precision:.2f}\")\n",
    "print(f\"LOO Subject CV sensitivity: {sensitivity:.2f}\")\n",
    "print(f\"LOO Subject CV specificity: {specificity :.2f}\")\n",
    "print(f\"LOO Subject CV Area under the ROC: {roc_auc :.2f}\")\n",
    "print(confusion_matrix(true_labels, predictions))\n",
    "\n",
    "# roc_display = RocCurveDisplay.from_predictions(true_labels, predictions)\n",
    "# roc_display = RocCurveDisplay(fpr=roc_auc[0], tpr=roc_auc[1], roc_auc=roc_auc[2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results Binary classification of RBD (1) vs healthy controls (0)\n",
    "\n",
    "RandomForestClassifier(class_weight='balanced', n_estimators=10)\n",
    "SelectedCols = ['MeanSpeed','velocityDecay']\n",
    "LOO Subject CV Accuracy: 0.79\n",
    "LOO Subject CV Accuracy: 0.78\n",
    "LOO Subject CV F1-score: 0.79\n",
    "LOO Subject CV recall: 0.79\n",
    "LOO Subject CV precision: 0.80\n",
    "LOO Subject CV sensitivity: 0.74\n",
    "LOO Subject CV specificity: 0.81\n",
    "LOO Subject CV Area under the ROC: 0.78\n",
    "[[35  8]\n",
    " [ 5 14]]\n",
    "\n",
    "\n",
    "LogisticRegression(class_weight='balanced')\n",
    "SelectedCols = ['MeanSpeed','velocityDecay']\n",
    "LOO Subject CV Accuracy: 0.74\n",
    "LOO Subject CV Accuracy: 0.71\n",
    "LOO Subject CV F1-score: 0.73\n",
    "LOO Subject CV recall: 0.73\n",
    "LOO Subject CV precision: 0.75\n",
    "LOO Subject CV sensitivity: 0.68\n",
    "LOO Subject CV specificity: 0.74\n",
    "LOO Subject CV Area under the ROC: 0.71\n",
    "[[32 11]\n",
    " [ 6 13]]\n",
    "\n",
    "\n",
    "XGBClassifier\n",
    "SelectedCols = ['MeanSpeed','velocityDecay']\n",
    "LOO Subject CV Accuracy: 0.73\n",
    "LOO Subject CV Accuracy: 0.72\n",
    "LOO Subject CV F1-score: 0.72\n",
    "LOO Subject CV recall: 0.71\n",
    "LOO Subject CV precision: 0.75\n",
    "LOO Subject CV sensitivity: 0.74\n",
    "LOO Subject CV specificity: 0.70\n",
    "LOO Subject CV Area under the ROC: 0.72\n",
    "[[30 13]\n",
    " [ 5 14]]\n",
    "\n",
    "svm(class_weight='balanced')\n",
    "SelectedCols = ['MeanSpeed','velocityDecay']\n",
    "LOO Subject CV Accuracy: 0.83\n",
    "LOO Subject CV Accuracy: 0.77\n",
    "LOO Subject CV F1-score: 0.81\n",
    "LOO Subject CV recall: 0.81\n",
    "LOO Subject CV precision: 0.81\n",
    "LOO Subject CV sensitivity: 0.68\n",
    "LOO Subject CV specificity: 0.86\n",
    "LOO Subject CV Area under the ROC: 0.77\n",
    "[[37  6]\n",
    " [ 6 13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1752,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO Subject CV Accuracy: 0.83\n",
      "LOO Subject CV Accuracy: 0.84\n",
      "LOO Subject CV F1-score: 0.83\n",
      "LOO Subject CV recall: 0.83\n",
      "LOO Subject CV precision: 0.85\n",
      "LOO Subject CV sensitivity: 0.94\n",
      "LOO Subject CV specificity: 0.74\n",
      "LOO Subject CV Area under the ROC: 0.84\n",
      "[[14  5]\n",
      " [ 1 15]]\n"
     ]
    }
   ],
   "source": [
    "# Binary classification of RBD (0) vs PD (1)\n",
    "\n",
    "#Apply SMOTE and RandomUnderSampler\n",
    "over = SMOTE(random_state=1)\n",
    "under = RandomUnderSampler(random_state=42)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipe = Pipeline(steps=steps)\n",
    "\n",
    "# Define subjects\n",
    "subjects = DataControls['ID'].tolist() + DataRBD['ID'].tolist()\n",
    "\n",
    "# Create a dictionary to map each sample to its subject\n",
    "sample_to_subject = {i: subjects[i] for i in range(len(subjects))}\n",
    "\n",
    "# Define a function to get unique subjects\n",
    "def get_unique_subjects(y):\n",
    "    return list(set([sample_to_subject[i] for i in range(len(y))]))\n",
    "\n",
    "# Define a function to get indices for a given subject\n",
    "def get_subject_indices(subject, y):\n",
    "    return [i for i in range(len(y)) if sample_to_subject[i] == subject]\n",
    "\n",
    "# Get unique subjects\n",
    "unique_subjects = get_unique_subjects(yRP)\n",
    "\n",
    "\n",
    "# model, scale = LogisticRegression(class_weight='balanced'), True  ##need to scale data \n",
    "# model, scale = svm.SVC(class_weight='balanced'), True  ##need to scale data \n",
    "model, scale = RandomForestClassifier(n_estimators=30, class_weight='balanced'), False ##no need to scale data \n",
    "# model, scale = EasyEnsembleClassifier(n_estimators=20), False ##no need to scale data\n",
    "# model, scale =   XGBClassifier(objective= 'binary:logistic',seed=42,n_jobs=-1,nthread=1,early_stopping_rounds=None,eval_metric='logloss',use_label_encoder=False,verbosity=0,class_weight='balanced'), False\n",
    "\n",
    "# model, scale =  XGBClassifier(\n",
    "#     n_estimators=5,\n",
    "#     objective='binary:logistic',\n",
    "#     scale_pos_weight=(len(yCR) - np.sum(yCR)) / np.sum(yCR),\n",
    "#     max_delta_step=1,\n",
    "# ), False\n",
    "\n",
    "# Initialize list to store predictions\n",
    "predictions = []\n",
    "true_labels = []\n",
    "accuracies = []\n",
    "# Perform Leave-One-Subject-Out CV\n",
    "\n",
    "selected_cols = [0,1,2,3]\n",
    "selected_cols = [0,1] \n",
    "for subject in unique_subjects:\n",
    "\n",
    "    test_indices = get_subject_indices(subject, yRP)\n",
    "    train_indices = [i for i in range(len(yRP)) if i not in test_indices]\n",
    "\n",
    "    #test data from one subject\n",
    "    XCR = np.array(XRP)\n",
    "    X_test, y_test = XRP[:,selected_cols][test_indices,:], yRP[test_indices]\n",
    "    # Apply SMOTE to the training data\n",
    "    #SMOTE to augment the data\n",
    "    \n",
    "    X_train, y_train = SMOTE().fit_resample(XRP[:,selected_cols][train_indices,:], yRP[train_indices])\n",
    "    # X_train, y_train = pipe.fit_resample(XRP[:,selected_cols][train_indices,:], yRP[train_indices])\n",
    "    # X_train, y_train = XRP[:,selected_cols][train_indices,:], yRP[train_indices]\n",
    "    ## Scale the data\n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "        # Fit the model\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    predictions.extend(y_pred)\n",
    "    true_labels.extend(y_test)\n",
    "     # Calculate accuracy\n",
    "\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # print(len(y_test), subject, accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = balanced_accuracy_score(true_labels, predictions)\n",
    "f1score = f1_score(true_labels, predictions, average = 'weighted')\n",
    "recall = recall_score(true_labels, predictions, average = 'weighted')\n",
    "precision = precision_score(true_labels, predictions, average='weighted')\n",
    "tn, fp, fn, tp = confusion_matrix(true_labels, predictions).ravel()\n",
    "sensitivity = tp /(tp+fn)\n",
    "specificity = tn / (tn+fp)\n",
    "roc_auc = roc_auc_score(true_labels, predictions)\n",
    "print(f\"LOO Subject CV Accuracy: {np.mean(accuracies):.2f}\")\n",
    "print(f\"LOO Subject CV Accuracy: {accuracy:.2f}\")\n",
    "print(f\"LOO Subject CV F1-score: {f1score:.2f}\")\n",
    "print(f\"LOO Subject CV recall: {recall:.2f}\")\n",
    "print(f\"LOO Subject CV precision: {precision:.2f}\")\n",
    "print(f\"LOO Subject CV sensitivity: {sensitivity:.2f}\")\n",
    "print(f\"LOO Subject CV specificity: {specificity :.2f}\")\n",
    "print(f\"LOO Subject CV Area under the ROC: {roc_auc :.2f}\")\n",
    "print(confusion_matrix(true_labels, predictions))\n",
    "\n",
    "# roc_display = RocCurveDisplay.from_predictions(true_labels, predictions)\n",
    "# roc_display = RocCurveDisplay(fpr=roc_auc[0], tpr=roc_auc[1], roc_auc=roc_auc[2])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results Binary classification of RBD (0) vs PD (1)\n",
    "\n",
    "RandomForestClassifier(class_weight='balanced', n_estimators=20)\n",
    "SelectedCols = ['MeanAmplitude','MeanSpeed']\n",
    "LOO Subject CV Accuracy: 0.83\n",
    "LOO Subject CV Accuracy: 0.84\n",
    "LOO Subject CV F1-score: 0.83\n",
    "LOO Subject CV recall: 0.83\n",
    "LOO Subject CV precision: 0.85\n",
    "LOO Subject CV sensitivity: 0.94\n",
    "LOO Subject CV specificity: 0.74\n",
    "LOO Subject CV Area under the ROC: 0.84\n",
    "[[14  5]\n",
    " [ 1 15]]\n",
    "\n",
    "\n",
    "LogisticRegression(class_weight='balanced')\n",
    "SelectedCols = ['MeanAmplitude','MeanSpeed']\n",
    "LOO Subject CV Accuracy: 0.71\n",
    "LOO Subject CV Accuracy: 0.77\n",
    "LOO Subject CV F1-score: 0.77\n",
    "LOO Subject CV recall: 0.77\n",
    "LOO Subject CV precision: 0.78\n",
    "LOO Subject CV sensitivity: 0.81\n",
    "LOO Subject CV specificity: 0.74\n",
    "LOO Subject CV Area under the ROC: 0.77\n",
    "[[14  5]\n",
    " [ 3 13]]\n",
    "\n",
    "\n",
    "svm(class_weight='balanced')\n",
    "SelectedCols = ['MeanAmplitude','MeanSpeed']\n",
    "LOO Subject CV Accuracy: 0.71\n",
    "LOO Subject CV Accuracy: 0.78\n",
    "LOO Subject CV F1-score: 0.77\n",
    "LOO Subject CV recall: 0.77\n",
    "LOO Subject CV precision: 0.79\n",
    "LOO Subject CV sensitivity: 0.88\n",
    "LOO Subject CV specificity: 0.68\n",
    "LOO Subject CV Area under the ROC: 0.78\n",
    "[[13  6]\n",
    " [ 2 14]]\n",
    "\n",
    "XGBClassifier\n",
    "SelectedCols = ['MeanAmplitude','MeanSpeed']\n",
    "LOO Subject CV Accuracy: 0.77\n",
    "LOO Subject CV Accuracy: 0.82\n",
    "LOO Subject CV F1-score: 0.80\n",
    "LOO Subject CV recall: 0.80\n",
    "LOO Subject CV precision: 0.86\n",
    "LOO Subject CV sensitivity: 1.00\n",
    "LOO Subject CV specificity: 0.63\n",
    "LOO Subject CV Area under the ROC: 0.82\n",
    "[[12  7]\n",
    " [ 0 16]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
